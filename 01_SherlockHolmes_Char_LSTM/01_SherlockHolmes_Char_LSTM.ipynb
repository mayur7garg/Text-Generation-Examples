{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset, AUTOTUNE\n",
    "from tensorflow.keras.layers import TextVectorization, LSTM, Embedding, Dropout, Dense, LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.train import Checkpoint, CheckpointManager\n",
    "\n",
    "from model_utility import get_train_val_data, generate_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-31 16:20:52.512874: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-31 16:20:52.545029: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-31 16:20:52.545364: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-31 16:20:52.546230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'compute_capability': (7, 5), 'device_name': 'NVIDIA GeForce GTX 1650'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.get_device_details(gpu_devices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jul 31 16:20:53 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.57       Driver Version: 516.59       CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   51C    P0    12W /  N/A |      0MiB /  4096MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 7\n",
    "SEQ_LEN = 512\n",
    "VAL_SIZE = 0.05\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "LR = 1e-3\n",
    "SHUFFLE_BUFFER = BATCH_SIZE * 20\n",
    "EMBEDDING_DIM = 32\n",
    "DROPOUT_RATIO = 0.2\n",
    "TRAIN_STEPS = 4000\n",
    "EARLY_STOP_PATIENCE = 5\n",
    "CHARS_TO_PREDICT = 256\n",
    "MODEL_IDENTIFIER = \"V1\"\n",
    "\n",
    "TB_LOGS = Path(\"tb_logs/\" + MODEL_IDENTIFIER)\n",
    "TB_LOGS.mkdir(exist_ok = True, parents = True)\n",
    "\n",
    "MODELS_DIR = Path(\"models/\" + MODEL_IDENTIFIER)\n",
    "MODELS_DIR.mkdir(exist_ok = True, parents = True)\n",
    "\n",
    "CKPT_DIR = Path(\"ckpt/\" + MODEL_IDENTIFIER)\n",
    "CKPT_DIR.mkdir(exist_ok = True, parents = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1647675, 1647675, 86720, 86720)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = get_train_val_data(\n",
    "    book_dir = Path(\"../Data/Text/Sherlock_Holmes/\"),\n",
    "    file_pat = \"*.txt\",\n",
    "    seq_len = SEQ_LEN,\n",
    "    val_size = VAL_SIZE,\n",
    "    random_state = RANDOM_STATE\n",
    ")\n",
    "\n",
    "len(X_train), len(y_train), len(X_val), len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Training data\n",
      "\n",
      "Input: 't to my illustrious client. “‘You doubt its value?’ he asked. “‘Not at all. I only doubt—’ “‘The propriety of my leaving it. You may set your mind at rest about that. I should not dream of doing so were it not absolutely certain that I should be able in four days to reclaim it. It is a pure matter of form. Is the security sufficient?’ “‘Ample.’ “‘You understand, Mr. Holder, that I am giving you a strong proof of the confidence which I have in you, founded upon all that I have heard of you. I rely upon you n'\n",
      "Output: 'o'\n",
      "\n",
      "Input: 'uble-edged weapon now. The chances are that she would be as averse to its being seen by Mr. Godfrey Norton, as our client is to its coming to the eyes of his princess. Now the question is, Where are we to find the photograph?” “Where, indeed?” “It is most unlikely that she carries it about with her. It is cabinet size. Too large for easy concealment about a woman’s dress. She knows that the King is capable of having her waylaid and searched. Two attempts of the sort have already been made. We may take it, t'\n",
      "Output: 'h'\n",
      "\n",
      "Input: 'never know what turn events might take afterwards. Thank you, Mr. Sandeford; here is your money, and I wish you a very good evening.” When our visitor had disappeared, Sherlock Holmes’s movements were such as to rivet our attention. He began by taking a clean white cloth from a drawer and laying it over the table. Then he placed his newly acquired bust in the centre of the cloth. Finally, he picked up his hunting-crop and struck Napoleon a sharp blow on the top of the head. The figure broke into fragments, '\n",
      "Output: 'a'\n",
      "\n",
      "Input: 'heat and run down to Croydon with me on the off chance of a case for your annals?” “I was longing for something to do.” “You shall have it then. Ring for our boots and tell them to order a cab. I’ll be back in a moment when I have changed my dressing-gown and filled my cigar-case.” A shower of rain fell while we were in the train, and the heat was far less oppressive in Croydon than in town. Holmes had sent on a wire, so that Lestrade, as wiry, as dapper, and as ferret-like as ever, was waiting for us at th'\n",
      "Output: 'e'\n",
      "\n",
      "Input: '” he said. “Theories are all very well, but we have to deal with a hard-headed British jury.” “_Nous verrons_,” answered Holmes calmly. “You work your own method, and I shall work mine. I shall be busy this afternoon, and shall probably return to London by the evening train.” “And leave your case unfinished?” “No, finished.” “But the mystery?” “It is solved.” “Who was the criminal, then?” “The gentleman I describe.” “But who is he?” “Surely it would not be difficult to find out. This is not such a populous '\n",
      "Output: 'n'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample Training data\\n\")\n",
    "\n",
    "for i in np.random.randint(len(X_train), size = (5)):\n",
    "    print(f\"Input: {X_train[i]!r}\")\n",
    "    print(f\"Output: {y_train[i]!r}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Validation data\n",
      "\n",
      "Input: 'pology to that noble lad, your son, who has carried himself in this matter as I should be proud to see my own son do, should I ever chance to have one.” “Then it was not Arthur who took them?” “I told you yesterday, and I repeat to-day, that it was not.” “You are sure of it! Then let us hurry to him at once to let him know that the truth is known.” “He knows it already. When I had cleared it all up I had an interview with him, and finding that he would not tell me the story, I told it to him, on which he ha'\n",
      "Output: 'd'\n",
      "\n",
      "Input: 'as wonderfully like a tiger himself. “I wonder that my very simple stratagem could deceive so old a _shikari_,” said Holmes. “It must be very familiar to you. Have you not tethered a young kid under a tree, lain above it with your rifle, and waited for the bait to bring up your tiger? This empty house is my tree, and you are my tiger. You have possibly had other guns in reserve in case there should be several tigers, or in the unlikely supposition of your own aim failing you. These,” he pointed around, “are'\n",
      "Output: ' '\n",
      "\n",
      "Input: 'ght him along to the cells, and his box as well, for we thought there might be something incriminating; but, bar a big sharp knife such as most sailors have, we got nothing for our trouble. However, we find that we shall want no more evidence, for on being brought before the inspector at the station he asked leave to make a statement, which was, of course, taken down, just as he made it, by our shorthand man. We had three copies typewritten, one of which I enclose. The affair proves, as I always thought it '\n",
      "Output: 'w'\n",
      "\n",
      "Input: 's Mr. Sherlock Holmes here?” My friend bowed and smiled. “Mr. Sandeford, of Reading, I suppose?” said he. “Yes, sir, I fear that I am a little late, but the trains were awkward. You wrote to me about a bust that is in my possession.” “Exactly.” “I have your letter here. You said, ‘I desire to possess a copy of Devine’s Napoleon, and am prepared to pay you ten pounds for the one which is in your possession.’ Is that right?” “Certainly.” “I was very much surprised at your letter, for I could not imagine how y'\n",
      "Output: 'o'\n",
      "\n",
      "Input: '. A broad wheal from an old scar ran right across it from eye to chin, and by its contraction had turned up one side of the upper lip, so that three teeth were exposed in a perpetual snarl. A shock of very bright red hair grew low over his eyes and forehead. “He’s a beauty, isn’t he?” said the inspector. “He certainly needs a wash,” remarked Holmes. “I had an idea that he might, and I took the liberty of bringing the tools with me.” He opened the Gladstone bag as he spoke, and took out, to my astonishment, '\n",
      "Output: 'a'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample Validation data\\n\")\n",
    "\n",
    "for i in np.random.randint(len(X_val), size = (5)):\n",
    "    print(f\"Input: {X_val[i]!r}\")\n",
    "    print(f\"Output: {y_val[i]!r}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ', 304968),\n",
       " ('e', 156016),\n",
       " ('t', 112813),\n",
       " ('a', 101601),\n",
       " ('o', 98866),\n",
       " ('n', 83866),\n",
       " ('h', 80282),\n",
       " ('i', 77695),\n",
       " ('s', 77640),\n",
       " ('r', 72685),\n",
       " ('d', 53723),\n",
       " ('l', 48901),\n",
       " ('u', 38652),\n",
       " ('m', 32673),\n",
       " ('c', 31331),\n",
       " ('w', 30771),\n",
       " ('f', 26089),\n",
       " ('y', 25704),\n",
       " ('g', 22231),\n",
       " (',', 21892)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_freq_dict = Counter(y_train)\n",
    "char_freq_dict.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-31 16:20:57.820852: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-31 16:20:57.823018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-31 16:20:57.823584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-31 16:20:57.824009: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-31 16:20:59.273870: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-31 16:20:59.274265: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-31 16:20:59.274286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-07-31 16:20:59.274622: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-31 16:20:59.274695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2103 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 863 ms, sys: 280 ms, total: 1.14 s\n",
      "Wall time: 2.03 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "vectorizer = TextVectorization(standardize = None, split = \"character\", name = 'TextVectorizer')\n",
    "vocab_json = Path(\"vocab.json\")\n",
    "\n",
    "if vocab_json.exists():\n",
    "    with vocab_json.open(\"r\") as vocab_file:\n",
    "        vocab = json.load(vocab_file)[\"vocab\"]\n",
    "    \n",
    "    vectorizer.set_vocabulary(vocab)\n",
    "else:\n",
    "    vectorizer.adapt(X_train)\n",
    "    vocab = vectorizer.get_vocabulary()[2:]\n",
    "\n",
    "    with vocab_json.open(\"w\") as vocab_file:\n",
    "        json.dump({\"vocab\": vocab}, vocab_file)\n",
    "\n",
    "vocab = vectorizer.get_vocabulary()\n",
    "char_count = len(vocab)\n",
    "char_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class ID    Char      Freq      Class weight\n",
      "     0          ''        1        124.68   \n",
      "     1       '[UNK]'      1        124.68   \n",
      "     2         ' '      304968      0.23    \n",
      "     3         'e'      156016      0.32    \n",
      "     4         't'      112813      0.37    \n",
      "     5         'a'      101601      0.39    \n",
      "     6         'o'      98866       0.4     \n",
      "     7         'n'      83866       0.43    \n",
      "     8         'h'      80282       0.44    \n",
      "     9         'i'      77695       0.45    \n",
      "     10        's'      77640       0.45    \n",
      "     11        'r'      72685       0.46    \n",
      "     12        'd'      53723       0.54    \n",
      "     13        'l'      48901       0.56    \n",
      "     14        'u'      38652       0.63    \n",
      "     15        'm'      32673       0.69    \n",
      "     16        'c'      31331       0.7     \n",
      "     17        'w'      30771       0.71    \n",
      "     18        'f'      26089       0.77    \n",
      "     19        'y'      25704       0.78    \n",
      "     20        'g'      22231       0.84    \n",
      "     21        ','      21892       0.84    \n",
      "     22        'p'      20013       0.88    \n",
      "     23        '.'      18509       0.92    \n",
      "     24        'b'      17169       0.95    \n",
      "     25        'v'      12643       1.11    \n",
      "     26        'I'      10556       1.21    \n",
      "     27        'k'      10355       1.23    \n",
      "     28        '“'       7216       1.47    \n",
      "     29        '”'       6110       1.6     \n",
      "     30        'H'       4024       1.97    \n",
      "     31        'T'       3678       2.06    \n",
      "     32        '’'       3097       2.24    \n",
      "     33        'W'       2479       2.5     \n",
      "     34        'A'       2228       2.64    \n",
      "     35        '-'       2178       2.67    \n",
      "     36        'M'       2186       2.67    \n",
      "     37        'S'       2171       2.68    \n",
      "     38        '?'       2077       2.74    \n",
      "     39        'x'       1907       2.86    \n",
      "     40        'B'       1436       3.29    \n",
      "     41        'Y'       1320       3.43    \n",
      "     42        'q'       1130       3.71    \n",
      "     43        'C'       1123       3.72    \n",
      "     44        'j'       1105       3.75    \n",
      "     45        'N'       1063       3.82    \n",
      "     46        '‘'       1058       3.83    \n",
      "     47        'E'       1015       3.91    \n",
      "     48        'L'       1015       3.91    \n",
      "     49        'O'       1007       3.93    \n",
      "     50        'P'       936        4.08    \n",
      "     51        '!'       878        4.21    \n",
      "     52        'G'       795        4.42    \n",
      "     53        '—'       777        4.47    \n",
      "     54        'F'       733        4.61    \n",
      "     55        'D'       729        4.62    \n",
      "     56        'R'       632        4.96    \n",
      "     57        'z'       471        5.74    \n",
      "     58        '_'       429        6.02    \n",
      "     59        ';'       347        6.69    \n",
      "     60        'J'       342        6.74    \n",
      "     61        '1'       284        7.4     \n",
      "     62        'U'       239        8.06    \n",
      "     63        'V'       204        8.73    \n",
      "     64        ':'       182        9.24    \n",
      "     65        '0'       158        9.92    \n",
      "     66        'K'       161        9.83    \n",
      "     67        '8'       108        12.0    \n",
      "     68        '2'        82       13.77    \n",
      "     69        '3'        80       13.94    \n",
      "     70        '*'        72       14.69    \n",
      "     71        ')'        74       14.49    \n",
      "     72        '('        76        14.3    \n",
      "     73        '4'        74       14.49    \n",
      "     74        '5'        74       14.49    \n",
      "     75        '9'        56       16.66    \n",
      "     76        '6'        54       16.97    \n",
      "     77        '/'        59       16.23    \n",
      "     78        'Q'        55       16.81    \n",
      "     79        '7'        50       17.63    \n",
      "     80        '£'        37        20.5    \n",
      "     81        'X'        25       24.94    \n",
      "     82        'é'        23        26.0    \n",
      "     83        '\"'        21       27.21    \n",
      "     84        '&'        18       29.39    \n",
      "     85        \"'\"        10       39.43    \n",
      "     86        'æ'        9        41.56    \n",
      "     87        '\\t'       8        44.08    \n",
      "     88        '$'        6         50.9    \n",
      "     89        'Z'        6         50.9    \n",
      "     90        '@'        5        55.76    \n",
      "     91        'œ'        5        55.76    \n",
      "     92        'º'        4        62.34    \n",
      "     93        ']'        1        124.68   \n",
      "     94        '['        1        124.68   \n",
      "     95        'è'        3        71.98    \n",
      "     96        '・'        3        71.98    \n",
      "     97        '%'        3        71.98    \n",
      "     98        '#'        1        124.68   \n",
      "     99        'à'        2        88.16    \n",
      "    100        'â'        2        88.16    \n",
      "    101        'ô'        2        88.16    \n",
      "    102        'ï'        1        124.68   \n",
      "    103        'î'        1        124.68   \n",
      "    104        '½'        1        124.68   \n",
      "    105      '\\ufeff'     1        124.68   \n"
     ]
    }
   ],
   "source": [
    "class_weight_dict = {}\n",
    "total_freq = sum([v for v in char_freq_dict.values()])\n",
    "\n",
    "print(f'{\"Class ID\":12}{\"Char\":10}{\"Freq\":10}{\"Class weight\"}')\n",
    "for i, v in enumerate(vocab):\n",
    "    freq = char_freq_dict.get(v, 1)\n",
    "    class_weight_dict[i] = round(np.sqrt(total_freq / (freq * char_count)), 2)\n",
    "    print(f\"{i:^12}{v!r:^10}{freq:^10}{class_weight_dict[i]:^12}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1647675,), (86720,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = vectorizer(y_train).numpy().flatten()\n",
    "y_val = vectorizer(y_val).numpy().flatten()\n",
    "y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = Dataset.from_tensor_slices((X_train, y_train)).shuffle(SHUFFLE_BUFFER).repeat().batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>,\n",
       " <tf.Tensor: shape=(), dtype=int64, numpy=678>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ds = Dataset.from_tensor_slices((X_val, y_val)).shuffle(SHUFFLE_BUFFER).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "val_ds, val_ds.cardinality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Text_Generation_Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 1)]               0         \n",
      "                                                                 \n",
      " TextVectorizer (TextVectori  (None, None)             0         \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " EmbeddingLayer (Embedding)  (None, None, 32)          3424      \n",
      "                                                                 \n",
      " LSTM_1 (LSTM)               (None, None, 512)         1116160   \n",
      "                                                                 \n",
      " LSTM_2 (LSTM)               (None, 256)               787456    \n",
      "                                                                 \n",
      " BN_1 (BatchNormalization)   (None, 256)               1024      \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " LR_1 (LeakyReLU)            (None, 256)               0         \n",
      "                                                                 \n",
      " Dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " Dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " LR_2 (LeakyReLU)            (None, 128)               0         \n",
      "                                                                 \n",
      " Dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " BN_2 (BatchNormalization)   (None, 128)               512       \n",
      "                                                                 \n",
      " Dense_3 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " LR_3 (LeakyReLU)            (None, 128)               0         \n",
      "                                                                 \n",
      " Output (Dense)              (None, 106)               13674     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,037,450\n",
      "Trainable params: 2,036,682\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_lstm_model(char_count: int, embedding_dim: int = 32):\n",
    "    input_layer = tf.keras.Input(shape = (1,), dtype = tf.string, name = 'Input')\n",
    "\n",
    "    vectorizer_layer = vectorizer(input_layer)\n",
    "    embedding_layer = Embedding(char_count + 1, embedding_dim, name = 'EmbeddingLayer')(vectorizer_layer)\n",
    "\n",
    "    lstm_1 = LSTM(512, return_sequences = True, dropout = DROPOUT_RATIO, name = 'LSTM_1')(embedding_layer)\n",
    "    lstm_2 = LSTM(256, dropout = DROPOUT_RATIO, name = 'LSTM_2')(lstm_1)\n",
    "    bn_1 = BatchNormalization(name = 'BN_1')(lstm_2)\n",
    "\n",
    "    dense_1 = Dense(256, name = 'Dense_1')(bn_1)\n",
    "    lr_1 = LeakyReLU(name = 'LR_1')(dense_1)\n",
    "    dropout_1 = Dropout(DROPOUT_RATIO, name = 'Dropout_1')(lr_1)\n",
    "\n",
    "    dense_2 = Dense(128, name = 'Dense_2')(dropout_1)\n",
    "    lr_2 = LeakyReLU(name = 'LR_2')(dense_2)\n",
    "    dropout_2 = Dropout(DROPOUT_RATIO, name = 'Dropout_2')(lr_2)\n",
    "    bn_2 = BatchNormalization(name = 'BN_2')(dropout_2)\n",
    "\n",
    "    dense_3 = Dense(128, name = 'Dense_3')(bn_2)\n",
    "    lr_3 = LeakyReLU(name = 'LR_3')(dense_3)\n",
    "\n",
    "    output_layer = Dense(char_count, activation = 'softmax', name = \"Output\")(lr_3)\n",
    "\n",
    "    model = tf.keras.Model(inputs  = input_layer, outputs = output_layer, name = 'Text_Generation_Model')\n",
    "    model.compile(optimizer = Adam(LR), loss = 'sparse_categorical_crossentropy', metrics = ['sparse_categorical_accuracy'])\n",
    "    return model\n",
    "\n",
    "model = get_lstm_model(char_count, EMBEDDING_DIM)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from Epoch 0\n"
     ]
    }
   ],
   "source": [
    "EPOCH_START = 0\n",
    "\n",
    "checkpoint = Checkpoint(\n",
    "    step = tf.Variable(EPOCH_START),\n",
    "    model = model\n",
    ")\n",
    "\n",
    "ckpt_manager = CheckpointManager(checkpoint, CKPT_DIR, max_to_keep = 3)\n",
    "\n",
    "if CKPT_DIR.joinpath(\"checkpoint\").exists():\n",
    "    checkpoint.restore(ckpt_manager.latest_checkpoint)\n",
    "    EPOCH_START = checkpoint.step.numpy()\n",
    "\n",
    "print(f\"Starting training from Epoch {EPOCH_START}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-31 16:21:26.048809: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 133s 189ms/step - loss: 4.6633 - sparse_categorical_accuracy: 0.0084\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.663280010223389, 0.008371771313250065]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "ile I sat opposite to him, and we listened in silence to the strange story which our visitor detailed to us. “You must know,” said he, “that I am an orphan and a bachelor, residing alone in lodgings in London. By profession I am a hydraulic engineer, and I have had considerable experience of my work during the seven years that I was apprenticed to Venner & Matheson, the well-known firm, of Greenwich. Two years ago, having served my time, and having also come into a fair sum of money through my poor father’s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4407c21903aa4e52b9dca7d7ba301610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting chars:   0%|          | 0/256 [00:00<?, ? char/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "ïïï:bbbbbbbbbbbbbbb111111ïïïïjbbbbbbbbbbbbbbbbbb111111ïïïïïbbbbbbbbbbbbbbbbbb111111ïïïïjbbbbbbbbbbbbbbbbbb111111ïïïïïbbbbbbbbbbbbbbbbbb111111ïïïïjbbbbbbbbbbbbbbbbbb111111ïïïïïbbbbbbbbbbbbbbbbbb111111ïïïïjbbbbbbbbbbbbbbbbbb111111ïïïïïbbbbbbbbbbbbbbbbbb11111\n",
      "CPU times: user 28.8 s, sys: 6.44 s, total: 35.2 s\n",
      "Wall time: 31.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sample_input = X_train[np.random.randint(len(X_train))]\n",
    "print(f\"Input:\\n{sample_input}\")\n",
    "print(f\"Output:\\n{generate_text(model, vocab, sample_input, CHARS_TO_PREDICT)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 2149s 536ms/step - loss: 2.1597 - sparse_categorical_accuracy: 0.1731 - val_loss: 3.0130 - val_sparse_categorical_accuracy: 0.1683\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 2150s 538ms/step - loss: 1.7489 - sparse_categorical_accuracy: 0.2583 - val_loss: 2.8990 - val_sparse_categorical_accuracy: 0.2405\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 2160s 540ms/step - loss: 1.5785 - sparse_categorical_accuracy: 0.3239 - val_loss: 2.2273 - val_sparse_categorical_accuracy: 0.3584\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 2160s 540ms/step - loss: 1.4457 - sparse_categorical_accuracy: 0.3736 - val_loss: 2.0643 - val_sparse_categorical_accuracy: 0.4037\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 2150s 538ms/step - loss: 1.3741 - sparse_categorical_accuracy: 0.4076 - val_loss: 1.8623 - val_sparse_categorical_accuracy: 0.4474\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 2147s 537ms/step - loss: 1.3125 - sparse_categorical_accuracy: 0.4341 - val_loss: 1.8135 - val_sparse_categorical_accuracy: 0.4643\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 2142s 535ms/step - loss: 1.2525 - sparse_categorical_accuracy: 0.4566 - val_loss: 1.8002 - val_sparse_categorical_accuracy: 0.4819\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 2149s 537ms/step - loss: 1.2211 - sparse_categorical_accuracy: 0.4685 - val_loss: 1.7229 - val_sparse_categorical_accuracy: 0.4856\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 2150s 538ms/step - loss: 1.1970 - sparse_categorical_accuracy: 0.4818 - val_loss: 1.6375 - val_sparse_categorical_accuracy: 0.5113\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 2153s 538ms/step - loss: 1.1594 - sparse_categorical_accuracy: 0.4946 - val_loss: 1.6098 - val_sparse_categorical_accuracy: 0.5175\n",
      "CPU times: user 4h 41s, sys: 1h 53min 39s, total: 5h 54min 20s\n",
      "Wall time: 5h 58min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "earlystop = EarlyStopping(patience = EARLY_STOP_PATIENCE, restore_best_weights = True)\n",
    "tensorboard = TensorBoard(log_dir = str(TB_LOGS))\n",
    "\n",
    "history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data = val_ds,\n",
    "        epochs = EPOCH_START + EPOCHS,\n",
    "        steps_per_epoch = TRAIN_STEPS,\n",
    "        class_weight = class_weight_dict,\n",
    "        initial_epoch = EPOCH_START,\n",
    "        callbacks = [earlystop, tensorboard]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 133s 197ms/step - loss: 1.6098 - sparse_categorical_accuracy: 0.5175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.6098037958145142, 0.5175046324729919]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "ile I sat opposite to him, and we listened in silence to the strange story which our visitor detailed to us. “You must know,” said he, “that I am an orphan and a bachelor, residing alone in lodgings in London. By profession I am a hydraulic engineer, and I have had considerable experience of my work during the seven years that I was apprenticed to Venner & Matheson, the well-known firm, of Greenwich. Two years ago, having served my time, and having also come into a fair sum of money through my poor father’s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89c8d29426942c8ac430cef7ededdef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting chars:   0%|          | 0/256 [00:00<?, ? char/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      " brown which I have been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been b\n",
      "CPU times: user 32 s, sys: 5.6 s, total: 37.6 s\n",
      "Wall time: 33.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(f\"Input:\\n{sample_input}\")\n",
    "print(f\"Output:\\n{generate_text(model, vocab, sample_input, CHARS_TO_PREDICT)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ckpt/V1/ckpt-1'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.step.assign_add(len(history.epoch))\n",
    "ckpt_manager.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    }
   ],
   "source": [
    "model.save(MODELS_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
