{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.notebook import trange\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset, AUTOTUNE\n",
    "from tensorflow.keras.layers import TextVectorization, LSTM, Embedding, Dropout, Dense, LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.train import Checkpoint, CheckpointManager\n",
    "\n",
    "from model_utility import get_train_val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-31 14:47:54.764926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-31 14:47:54.775597: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-31 14:47:54.775999: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-31 14:47:54.778320: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'compute_capability': (7, 5), 'device_name': 'NVIDIA GeForce GTX 1650'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.get_device_details(gpu_devices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jul 31 14:47:55 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.57       Driver Version: 516.59       CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   58C    P8     4W /  N/A |    234MiB /  4096MiB |     26%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 7\n",
    "SEQ_LEN = 512\n",
    "VAL_SIZE = 0.05\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "LR = 1e-3\n",
    "SHUFFLE_BUFFER = BATCH_SIZE * 20\n",
    "EMBEDDING_DIM = 32\n",
    "DROPOUT_RATIO = 0.2\n",
    "TRAIN_STEPS = 4000\n",
    "EARLY_STOP_PATIENCE = 5\n",
    "CHARS_TO_PREDICT = 256\n",
    "MODEL_IDENTIFIER = \"V1\"\n",
    "\n",
    "TB_LOGS = Path(\"tb_logs/\" + MODEL_IDENTIFIER)\n",
    "TB_LOGS.mkdir(exist_ok = True, parents = True)\n",
    "\n",
    "MODELS_DIR = Path(\"models/\" + MODEL_IDENTIFIER)\n",
    "MODELS_DIR.mkdir(exist_ok = True, parents = True)\n",
    "\n",
    "CKPT_DIR = Path(\"ckpt/\" + MODEL_IDENTIFIER)\n",
    "CKPT_DIR.mkdir(exist_ok = True, parents = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1647675, 1647675, 86720, 86720)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = get_train_val_data(\n",
    "    book_dir = Path(\"../Data/Text/Sherlock_Holmes/\"),\n",
    "    file_pat = \"*.txt\",\n",
    "    seq_len = SEQ_LEN,\n",
    "    val_size = VAL_SIZE,\n",
    "    random_state = RANDOM_STATE\n",
    ")\n",
    "\n",
    "len(X_train), len(y_train), len(X_val), len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Training data\n",
      "\n",
      "Input: 'rious,” he observed, as we drove to Scotland Yard. “These men have got hold of Melas again. He is a man of no physical courage, as they are well aware from their experience the other night. This villain was able to terrorise him the instant that he got into his presence. No doubt they want his professional services, but, having used him, they may be inclined to punish him for what they will regard as his treachery.” Our hope was that, by taking train, we might get to Beckenham as soon or sooner than the car'\n",
      "Output: 'r'\n",
      "\n",
      "Input: 'tion of nitrite of amyl, and the present seemed an admirable opportunity of testing its virtues. The bottle was downstairs in my laboratory, so leaving my patient seated in his chair, I ran down to get it. There was some little delay in finding it—five minutes, let us say—and then I returned. Imagine my amazement to find the room empty and the patient gone. “Of course, my first act was to run into the waiting-room. The son had gone also. The hall door had been closed, but not shut. My page who admits patien'\n",
      "Output: 't'\n",
      "\n",
      "Input: 'ly spelled with an ‘i,’ which has been changed to ‘y.’ The parcel was directed, then, by a man—the printing is distinctly masculine—of limited education and unacquainted with the town of Croydon. So far, so good! The box is a yellow half-pound honeydew box, with nothing distinctive save two thumb marks at the left bottom corner. It is filled with rough salt of the quality used for preserving hides and other of the coarser commercial purposes. And embedded in it are these very singular enclosures.” He took o'\n",
      "Output: 'u'\n",
      "\n",
      "Input: 's not exactly my own.” “I was aware of it,” said Holmes dryly. “The circumstances are of great delicacy, and every precaution has to be taken to quench what might grow to be an immense scandal and seriously compromise one of the reigning families of Europe. To speak plainly, the matter implicates the great House of Ormstein, hereditary kings of Bohemia.” “I was also aware of that,” murmured Holmes, settling himself down in his armchair and closing his eyes. Our visitor glanced with some apparent surprise at'\n",
      "Output: ' '\n",
      "\n",
      "Input: 'izened man darted out of it, like a rabbit out of its burrow. “Capital!” said Holmes, calmly. “Watson, a bucket of water over the straw. That will do! Lestrade, allow me to present you with your principal missing witness, Mr. Jonas Oldacre.” The detective stared at the newcomer with blank amazement. The latter was blinking in the bright light of the corridor, and peering at us and at the smouldering fire. It was an odious face—crafty, vicious, malignant, with shifty, light-grey eyes and white lashes. “What’'\n",
      "Output: 's'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample Training data\\n\")\n",
    "\n",
    "for i in np.random.randint(len(X_train), size = (5)):\n",
    "    print(f\"Input: {X_train[i]!r}\")\n",
    "    print(f\"Output: {y_train[i]!r}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Validation data\n",
      "\n",
      "Input: 'uplicates of the one which was destroyed in Morse Hudson’s shop?” “They were taken from the same mould.” “Such a fact must tell against the theory that the man who breaks them is influenced by any general hatred of Napoleon. Considering how many hundreds of statues of the great Emperor must exist in London, it is too much to suppose such a coincidence as that a promiscuous iconoclast should chance to begin upon three specimens of the same bust.” “Well, I thought as you do,” said Lestrade. “On the other hand'\n",
      "Output: ','\n",
      "\n",
      "Input: 'quest a description of his cabin, in which it stated that the old logbooks of his vessel were preserved in it. It struck me that if I could see what occurred in the month of August, 1883, on board the _Sea Unicorn_, I might settle the mystery of my father’s fate. I tried last night to get at these logbooks, but was unable to open the door. To-night I tried again and succeeded, but I find that the pages which deal with that month have been torn from the book. It was at that moment I found myself a prisoner i'\n",
      "Output: 'n'\n",
      "\n",
      "Input: 't undertake to say. He is taller than the Indian, not so tall as Gilchrist. I suppose five foot six would be about it.” “That is very important,” said Holmes. “And now, Mr. Soames, I wish you good-night.” Our guide cried aloud in his astonishment and dismay. “Good gracious, Mr. Holmes, you are surely not going to leave me in this abrupt fashion! You don’t seem to realize the position. To-morrow is the examination. I must take some definite action to-night. I cannot allow the examination to be held if one of'\n",
      "Output: ' '\n",
      "\n",
      "Input: 'e Foundation at the address specified in Section 4, “Information about donations to the Project Gutenberg Literary Archive Foundation.” - You provide a full refund of any money paid by a user who notifies you in writing (or by e-mail) within 30 days of receipt that s/he does not agree to the terms of the full Project Gutenberg-tm License. You must require such a user to return or destroy all copies of the works possessed in a physical medium and discontinue all use of and all access to other copies of Proje'\n",
      "Output: 'c'\n",
      "\n",
      "Input: '. The Colonel possessed a varied collection of weapons brought from the different countries in which he had fought, and it is conjectured by the police that his club was among his trophies. The servants deny having seen it before, but among the numerous curiosities in the house it is possible that it may have been overlooked. Nothing else of importance was discovered in the room by the police, save the inexplicable fact that neither upon Mrs. Barclay’s person nor upon that of the victim nor in any part of t'\n",
      "Output: 'h'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample Validation data\\n\")\n",
    "\n",
    "for i in np.random.randint(len(X_val), size = (5)):\n",
    "    print(f\"Input: {X_val[i]!r}\")\n",
    "    print(f\"Output: {y_val[i]!r}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ', 304968),\n",
       " ('e', 156016),\n",
       " ('t', 112813),\n",
       " ('a', 101601),\n",
       " ('o', 98866),\n",
       " ('n', 83866),\n",
       " ('h', 80282),\n",
       " ('i', 77695),\n",
       " ('s', 77640),\n",
       " ('r', 72685),\n",
       " ('d', 53723),\n",
       " ('l', 48901),\n",
       " ('u', 38652),\n",
       " ('m', 32673),\n",
       " ('c', 31331),\n",
       " ('w', 30771),\n",
       " ('f', 26089),\n",
       " ('y', 25704),\n",
       " ('g', 22231),\n",
       " (',', 21892)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_freq_dict = Counter(y_train)\n",
    "char_freq_dict.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.21 s, sys: 336 ms, total: 1.54 s\n",
      "Wall time: 2.09 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-31 14:48:01.293672: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-31 14:48:01.296089: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-31 14:48:01.296936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-31 14:48:01.297634: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-31 14:48:02.686881: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-31 14:48:02.687386: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-31 14:48:02.687418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-07-31 14:48:02.687940: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-31 14:48:02.688059: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2103 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "vectorizer = TextVectorization(standardize = None, split = \"character\", name = 'TextVectorizer')\n",
    "vocab_json = Path(\"vocab.json\")\n",
    "\n",
    "if vocab_json.exists():\n",
    "    with vocab_json.open(\"r\") as vocab_file:\n",
    "        vocab = json.load(vocab_file)[\"vocab\"]\n",
    "    \n",
    "    vectorizer.set_vocabulary(vocab)\n",
    "else:\n",
    "    vectorizer.adapt(X_train)\n",
    "    vocab = vectorizer.get_vocabulary()[2:]\n",
    "\n",
    "    with vocab_json.open(\"w\") as vocab_file:\n",
    "        json.dump({\"vocab\": vocab}, vocab_file)\n",
    "\n",
    "vocab = vectorizer.get_vocabulary()\n",
    "char_count = len(vocab)\n",
    "char_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class ID    Char      Freq      Class weight\n",
      "     0          ''        1        124.68   \n",
      "     1       '[UNK]'      1        124.68   \n",
      "     2         ' '      304968      0.23    \n",
      "     3         'e'      156016      0.32    \n",
      "     4         't'      112813      0.37    \n",
      "     5         'a'      101601      0.39    \n",
      "     6         'o'      98866       0.4     \n",
      "     7         'n'      83866       0.43    \n",
      "     8         'h'      80282       0.44    \n",
      "     9         'i'      77695       0.45    \n",
      "     10        's'      77640       0.45    \n",
      "     11        'r'      72685       0.46    \n",
      "     12        'd'      53723       0.54    \n",
      "     13        'l'      48901       0.56    \n",
      "     14        'u'      38652       0.63    \n",
      "     15        'm'      32673       0.69    \n",
      "     16        'c'      31331       0.7     \n",
      "     17        'w'      30771       0.71    \n",
      "     18        'f'      26089       0.77    \n",
      "     19        'y'      25704       0.78    \n",
      "     20        'g'      22231       0.84    \n",
      "     21        ','      21892       0.84    \n",
      "     22        'p'      20013       0.88    \n",
      "     23        '.'      18509       0.92    \n",
      "     24        'b'      17169       0.95    \n",
      "     25        'v'      12643       1.11    \n",
      "     26        'I'      10556       1.21    \n",
      "     27        'k'      10355       1.23    \n",
      "     28        '“'       7216       1.47    \n",
      "     29        '”'       6110       1.6     \n",
      "     30        'H'       4024       1.97    \n",
      "     31        'T'       3678       2.06    \n",
      "     32        '’'       3097       2.24    \n",
      "     33        'W'       2479       2.5     \n",
      "     34        'A'       2228       2.64    \n",
      "     35        '-'       2178       2.67    \n",
      "     36        'M'       2186       2.67    \n",
      "     37        'S'       2171       2.68    \n",
      "     38        '?'       2077       2.74    \n",
      "     39        'x'       1907       2.86    \n",
      "     40        'B'       1436       3.29    \n",
      "     41        'Y'       1320       3.43    \n",
      "     42        'q'       1130       3.71    \n",
      "     43        'C'       1123       3.72    \n",
      "     44        'j'       1105       3.75    \n",
      "     45        'N'       1063       3.82    \n",
      "     46        '‘'       1058       3.83    \n",
      "     47        'E'       1015       3.91    \n",
      "     48        'L'       1015       3.91    \n",
      "     49        'O'       1007       3.93    \n",
      "     50        'P'       936        4.08    \n",
      "     51        '!'       878        4.21    \n",
      "     52        'G'       795        4.42    \n",
      "     53        '—'       777        4.47    \n",
      "     54        'F'       733        4.61    \n",
      "     55        'D'       729        4.62    \n",
      "     56        'R'       632        4.96    \n",
      "     57        'z'       471        5.74    \n",
      "     58        '_'       429        6.02    \n",
      "     59        ';'       347        6.69    \n",
      "     60        'J'       342        6.74    \n",
      "     61        '1'       284        7.4     \n",
      "     62        'U'       239        8.06    \n",
      "     63        'V'       204        8.73    \n",
      "     64        ':'       182        9.24    \n",
      "     65        '0'       158        9.92    \n",
      "     66        'K'       161        9.83    \n",
      "     67        '8'       108        12.0    \n",
      "     68        '2'        82       13.77    \n",
      "     69        '3'        80       13.94    \n",
      "     70        '*'        72       14.69    \n",
      "     71        ')'        74       14.49    \n",
      "     72        '('        76        14.3    \n",
      "     73        '4'        74       14.49    \n",
      "     74        '5'        74       14.49    \n",
      "     75        '9'        56       16.66    \n",
      "     76        '6'        54       16.97    \n",
      "     77        '/'        59       16.23    \n",
      "     78        'Q'        55       16.81    \n",
      "     79        '7'        50       17.63    \n",
      "     80        '£'        37        20.5    \n",
      "     81        'X'        25       24.94    \n",
      "     82        'é'        23        26.0    \n",
      "     83        '\"'        21       27.21    \n",
      "     84        '&'        18       29.39    \n",
      "     85        \"'\"        10       39.43    \n",
      "     86        'æ'        9        41.56    \n",
      "     87        '\\t'       8        44.08    \n",
      "     88        '$'        6         50.9    \n",
      "     89        'Z'        6         50.9    \n",
      "     90        '@'        5        55.76    \n",
      "     91        'œ'        5        55.76    \n",
      "     92        'º'        4        62.34    \n",
      "     93        ']'        1        124.68   \n",
      "     94        '['        1        124.68   \n",
      "     95        'è'        3        71.98    \n",
      "     96        '・'        3        71.98    \n",
      "     97        '%'        3        71.98    \n",
      "     98        '#'        1        124.68   \n",
      "     99        'à'        2        88.16    \n",
      "    100        'â'        2        88.16    \n",
      "    101        'ô'        2        88.16    \n",
      "    102        'ï'        1        124.68   \n",
      "    103        'î'        1        124.68   \n",
      "    104        '½'        1        124.68   \n",
      "    105      '\\ufeff'     1        124.68   \n"
     ]
    }
   ],
   "source": [
    "class_weight_dict = {}\n",
    "total_freq = sum([v for v in char_freq_dict.values()])\n",
    "\n",
    "print(f'{\"Class ID\":12}{\"Char\":10}{\"Freq\":10}{\"Class weight\"}')\n",
    "for i, v in enumerate(vocab):\n",
    "    freq = char_freq_dict.get(v, 1)\n",
    "    class_weight_dict[i] = round(np.sqrt(total_freq / (freq * char_count)), 2)\n",
    "    print(f\"{i:^12}{v!r:^10}{freq:^10}{class_weight_dict[i]:^12}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1647675,), (86720,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = vectorizer(y_train).numpy().flatten()\n",
    "y_val = vectorizer(y_val).numpy().flatten()\n",
    "y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = Dataset.from_tensor_slices((X_train, y_train)).shuffle(SHUFFLE_BUFFER).repeat().batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>,\n",
       " <tf.Tensor: shape=(), dtype=int64, numpy=678>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ds = Dataset.from_tensor_slices((X_val, y_val)).shuffle(SHUFFLE_BUFFER).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "val_ds, val_ds.cardinality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Text_Generation_Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 1)]               0         \n",
      "                                                                 \n",
      " TextVectorizer (TextVectori  (None, None)             0         \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " EmbeddingLayer (Embedding)  (None, None, 32)          3424      \n",
      "                                                                 \n",
      " LSTM_1 (LSTM)               (None, None, 512)         1116160   \n",
      "                                                                 \n",
      " LSTM_2 (LSTM)               (None, 256)               787456    \n",
      "                                                                 \n",
      " BN_1 (BatchNormalization)   (None, 256)               1024      \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " LR_1 (LeakyReLU)            (None, 256)               0         \n",
      "                                                                 \n",
      " Dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " Dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " LR_2 (LeakyReLU)            (None, 128)               0         \n",
      "                                                                 \n",
      " Dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " BN_2 (BatchNormalization)   (None, 128)               512       \n",
      "                                                                 \n",
      " Dense_3 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " LR_3 (LeakyReLU)            (None, 128)               0         \n",
      "                                                                 \n",
      " Output (Dense)              (None, 106)               13674     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,037,450\n",
      "Trainable params: 2,036,682\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_lstm_model(char_count: int, embedding_dim: int = 32):\n",
    "    input_layer = tf.keras.Input(shape = (1,), dtype = tf.string, name = 'Input')\n",
    "\n",
    "    vectorizer_layer = vectorizer(input_layer)\n",
    "    embedding_layer = Embedding(char_count + 1, embedding_dim, name = 'EmbeddingLayer')(vectorizer_layer)\n",
    "\n",
    "    lstm_1 = LSTM(512, return_sequences = True, dropout = DROPOUT_RATIO, name = 'LSTM_1')(embedding_layer)\n",
    "    lstm_2 = LSTM(256, dropout = DROPOUT_RATIO, name = 'LSTM_2')(lstm_1)\n",
    "    bn_1 = BatchNormalization(name = 'BN_1')(lstm_2)\n",
    "\n",
    "    dense_1 = Dense(256, name = 'Dense_1')(bn_1)\n",
    "    lr_1 = LeakyReLU(name = 'LR_1')(dense_1)\n",
    "    dropout_1 = Dropout(DROPOUT_RATIO, name = 'Dropout_1')(lr_1)\n",
    "\n",
    "    dense_2 = Dense(128, name = 'Dense_2')(dropout_1)\n",
    "    lr_2 = LeakyReLU(name = 'LR_2')(dense_2)\n",
    "    dropout_2 = Dropout(DROPOUT_RATIO, name = 'Dropout_2')(lr_2)\n",
    "    bn_2 = BatchNormalization(name = 'BN_2')(dropout_2)\n",
    "\n",
    "    dense_3 = Dense(128, name = 'Dense_3')(bn_2)\n",
    "    lr_3 = LeakyReLU(name = 'LR_3')(dense_3)\n",
    "\n",
    "    output_layer = Dense(char_count, activation = 'softmax', name = \"Output\")(lr_3)\n",
    "\n",
    "    model = tf.keras.Model(inputs  = input_layer, outputs = output_layer, name = 'Text_Generation_Model')\n",
    "    model.compile(optimizer = Adam(LR), loss = 'sparse_categorical_crossentropy', metrics = ['sparse_categorical_accuracy'])\n",
    "    return model\n",
    "\n",
    "model = get_lstm_model(char_count, EMBEDDING_DIM)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from Epoch 3\n"
     ]
    }
   ],
   "source": [
    "EPOCH_START = 0\n",
    "\n",
    "checkpoint = Checkpoint(\n",
    "    step = tf.Variable(EPOCH_START),\n",
    "    model = model\n",
    ")\n",
    "\n",
    "ckpt_manager = CheckpointManager(checkpoint, CKPT_DIR, max_to_keep = 3)\n",
    "\n",
    "if CKPT_DIR.joinpath(\"checkpoint\").exists():\n",
    "    checkpoint.restore(ckpt_manager.latest_checkpoint)\n",
    "    EPOCH_START = checkpoint.step.numpy()\n",
    "\n",
    "print(f\"Starting training from Epoch {EPOCH_START}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-31 14:48:32.116721: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 153s 219ms/step - loss: 3.8485 - sparse_categorical_accuracy: 0.0478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.848475694656372, 0.04775138199329376]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "attacks of jealousy which have amounted to frenzy. It is conjectured that it was in one of these that she committed the terrible crime which has caused such a sensation in London. Her movements upon the Monday night have not yet been traced, but it is undoubted that a woman answering to her description attracted much attention at Charing Cross Station on Tuesday morning by the wildness of her appearance and the violence of her gestures. It is probable, therefore, that the crime was either committed when ins\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5676410005e246ff8a4c31f3fef40ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting chars:   0%|          | 0/256 [00:00<?, ? char/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\n",
      "CPU times: user 34.1 s, sys: 5.38 s, total: 39.5 s\n",
      "Wall time: 35.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sample_id = np.random.randint(len(X_train))\n",
    "sample_input = X_train[sample_id]\n",
    "print(f\"Input:\\n{sample_input}\")\n",
    "\n",
    "pred_output = ''\n",
    "\n",
    "for i in trange(CHARS_TO_PREDICT, desc = \"Predicting chars\", unit = \" char\"):\n",
    "    pred = model.predict([sample_input], verbose = False)\n",
    "    pred_char_id = pred.argmax()\n",
    "    pred_char = vocab[pred_char_id]\n",
    "    pred_output += pred_char\n",
    "    sample_input = sample_input[1:] + pred_char\n",
    "\n",
    "print(f\"Output:\\n{pred_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/6\n",
      "30/30 [==============================] - 169s 6s/step - loss: 2.3242 - sparse_categorical_accuracy: 0.0995 - val_loss: 3.9188 - val_sparse_categorical_accuracy: 0.0442\n",
      "Epoch 5/6\n",
      "30/30 [==============================] - 165s 6s/step - loss: 2.3022 - sparse_categorical_accuracy: 0.0940 - val_loss: 3.7665 - val_sparse_categorical_accuracy: 0.1852\n",
      "Epoch 6/6\n",
      "30/30 [==============================] - 165s 6s/step - loss: 2.2159 - sparse_categorical_accuracy: 0.0979 - val_loss: 3.7089 - val_sparse_categorical_accuracy: 0.0602\n",
      "CPU times: user 4min 37s, sys: 3min 11s, total: 7min 48s\n",
      "Wall time: 8min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "earlystop = EarlyStopping(patience = EARLY_STOP_PATIENCE, restore_best_weights = True)\n",
    "tensorboard = TensorBoard(log_dir = str(TB_LOGS))\n",
    "\n",
    "history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data = val_ds,\n",
    "        epochs = EPOCH_START + EPOCHS,\n",
    "        steps_per_epoch = TRAIN_STEPS,\n",
    "        class_weight = class_weight_dict,\n",
    "        initial_epoch = EPOCH_START,\n",
    "        callbacks = [earlystop, tensorboard]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 133s 196ms/step - loss: 3.7089 - sparse_categorical_accuracy: 0.0602\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.7088823318481445, 0.06015913188457489]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "attacks of jealousy which have amounted to frenzy. It is conjectured that it was in one of these that she committed the terrible crime which has caused such a sensation in London. Her movements upon the Monday night have not yet been traced, but it is undoubted that a woman answering to her description attracted much attention at Charing Cross Station on Tuesday morning by the wildness of her appearance and the violence of her gestures. It is probable, therefore, that the crime was either committed when ins\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a8dc67c4ab460580c074f020fb0cf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting chars:   0%|          | 0/256 [00:00<?, ? char/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "oooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo\n",
      "CPU times: user 36.1 s, sys: 5.59 s, total: 41.7 s\n",
      "Wall time: 37.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sample_input = X_train[sample_id]\n",
    "print(f\"Input:\\n{sample_input}\")\n",
    "\n",
    "pred_output = ''\n",
    "\n",
    "for i in trange(CHARS_TO_PREDICT, desc = \"Predicting chars\", unit = \" char\"):\n",
    "    pred = model.predict([sample_input], verbose = False)\n",
    "    pred_char_id = pred.argmax()\n",
    "    pred_char = vocab[pred_char_id]\n",
    "    pred_output += pred_char\n",
    "    sample_input = sample_input[1:] + pred_char\n",
    "\n",
    "print(f\"Output:\\n{pred_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ckpt/V1/ckpt-2'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.step.assign_add(len(history.epoch))\n",
    "ckpt_manager.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    }
   ],
   "source": [
    "model.save(MODELS_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
