{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import random\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.notebook import trange\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset, AUTOTUNE\n",
    "from tensorflow.keras.layers import TextVectorization, LSTM, Embedding, Dropout, Dense, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 18:34:37.915500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-26 18:34:37.924748: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-26 18:34:37.925227: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-26 18:34:37.928333: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'compute_capability': (7, 5), 'device_name': 'NVIDIA GeForce GTX 1650'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.get_device_details(gpu_devices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul 26 18:34:38 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.57       Driver Version: 516.59       CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   59C    P0    12W /  N/A |    186MiB /  4096MiB |     18%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 7\n",
    "SEQ_LEN = 512\n",
    "VAL_SIZE = 0.05\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "LR = 1e-3\n",
    "SHUFFLE_BUFFER = 1_000\n",
    "EMBEDDING_DIM = 32\n",
    "TRAIN_STEPS = 25\n",
    "VAL_STEPS = 10\n",
    "\n",
    "TB_LOGS = Path(\"tb_logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "TB_LOGS.mkdir(exist_ok = True, parents = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 'hat you have not slept for a night or two,” said\\n Holmes, in his easy, genial way. “That tries a man’s nerves more\\n than work, and more even than pleasure. May I ask how I can help\\n you?”\\n\\n “I wanted your advice, sir. I don’t know what to do and my whole\\n life seems to have gone to pieces.”\\n\\n “You wish to employ me as a consulting detective?”\\n\\n “Not that only. I want your opinion as a judicious man—as a man\\n of the world. I want to know what I ought to do next. I hope to\\n God you’ll be able to tell me.”\\n\\n H'\n",
      "Output: e\n",
      "\n",
      "Input: 'notebook, broke his pencil, had to borrow one\\n from our host and finally borrowed a knife to sharpen his own.\\n The same curious accident happened to him in the rooms of the\\n Indian—a silent, little, hook-nosed fellow, who eyed us askance,\\n and was obviously glad when Holmes’s architectural studies had\\n come to an end. I could not see that in either case Holmes had\\n come upon the clue for which he was searching. Only at the third\\n did our visit prove abortive. The outer door would not open to\\n our knock, and'\n",
      "Output:  \n",
      "\n",
      "Input: 'r of the responsibility\\n which devolved upon him in consequence of the great interests at\\n stake that safes of the very latest construction have been\\n employed, and an armed watchman has been left day and night in\\n the building. It appears that last week a new clerk named Hall\\n Pycroft was engaged by the firm. This person appears to have been\\n none other than Beddington, the famous forger and cracksman, who,\\n with his brother, had only recently emerged from a five years’\\n spell of penal servitude. By some m'\n",
      "Output: e\n",
      "\n",
      "Input: 'w, sir, whether you have\\n formed any explanation in your own mind as to the mysterious\\n disappearance of your son?”\\n\\n “No, sir, I have not.”\\n\\n “Excuse me if I allude to that which is painful to you, but I\\n have no alternative. Do you think that the Duchess had anything\\n to do with the matter?”\\n\\n The great minister showed perceptible hesitation.\\n\\n “I do not think so,” he said, at last.\\n\\n “The other most obvious explanation is that the child has been\\n kidnapped for the purpose of levying ransom. You have not '\n",
      "Output: h\n",
      "\n",
      "Input: 'ofit\\n a woman, for example, to get him a few months’ imprisonment if\\n her own ruin must immediately follow? His victims dare not hit\\n back. If ever he blackmailed an innocent person, then indeed we\\n should have him, but he is as cunning as the Evil One. No, no, we\\n must find other ways to fight him.”\\n\\n “And why is he here?”\\n\\n “Because an illustrious client has placed her piteous case in my\\n hands. It is the Lady Eva Blackwell, the most beautiful\\n _débutante_ of last season. She is to be married in a fortnig'\n",
      "Output: h\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "books = Path(\"../Data/Text/Sherlock_Holmes/\").rglob(\"*.txt\")\n",
    "\n",
    "for book in books:\n",
    "    with book.open('r', encoding = 'utf-8') as book_file:\n",
    "        book_data = book_file.read()\n",
    "        book_data = re.sub(\"[ ]+\", \" \", book_data)\n",
    "        char_len = len(book_data)\n",
    "\n",
    "        for i in range(0, char_len - SEQ_LEN):\n",
    "            X.append(book_data[i : i + SEQ_LEN])\n",
    "            y.append(book_data[i + SEQ_LEN])\n",
    "\n",
    "for i in np.random.randint(0, len(X), 5):\n",
    "    print(f'Input: {X[i]!r}')\n",
    "    print(f'Output: {y[i]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1762106, 1762106)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1674000, 1674000, 88106, 88106)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = VAL_SIZE, random_state = RANDOM_STATE)\n",
    "\n",
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ', 295464),\n",
       " ('e', 155851),\n",
       " ('t', 112814),\n",
       " ('a', 101599),\n",
       " ('o', 98853),\n",
       " ('n', 83839),\n",
       " ('h', 80451),\n",
       " ('i', 77714),\n",
       " ('s', 77639),\n",
       " ('r', 72665),\n",
       " ('d', 53827),\n",
       " ('l', 48896),\n",
       " ('u', 38653),\n",
       " ('\\n', 35880),\n",
       " ('m', 32644),\n",
       " ('c', 31278),\n",
       " ('w', 30752),\n",
       " ('f', 26027),\n",
       " ('y', 25655),\n",
       " ('g', 22287)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_freq_dict = Counter(y_train)\n",
    "char_freq_dict.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(X)\n",
    "del(y)\n",
    "del(book_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 18:34:43.044102: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-26 18:34:43.045408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-26 18:34:43.045978: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-26 18:34:43.046523: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-26 18:34:44.062042: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-26 18:34:44.062593: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-26 18:34:44.062611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-07-26 18:34:44.063042: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-26 18:34:44.063095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2103 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 774 ms, sys: 201 ms, total: 974 ms\n",
      "Wall time: 1.35 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "vectorizer = TextVectorization(standardize = None, split = \"character\", name = 'TextVectorizer')\n",
    "vocab_json = Path(\"vocab.json\")\n",
    "\n",
    "if vocab_json.exists():\n",
    "    with vocab_json.open(\"r\") as vocab_file:\n",
    "        vocab = json.load(vocab_file)[\"vocab\"]\n",
    "    \n",
    "    vectorizer.set_vocabulary(vocab)\n",
    "else:\n",
    "    vectorizer.adapt(X_train)\n",
    "    vocab = vectorizer.get_vocabulary()[2:]\n",
    "\n",
    "    with vocab_json.open(\"w\") as vocab_file:\n",
    "        json.dump({\"vocab\": vocab}, vocab_file)\n",
    "\n",
    "vocab = vectorizer.get_vocabulary()\n",
    "char_count = len(vocab)\n",
    "char_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1000.0,\n",
       " 1: 1000.0,\n",
       " 2: 0.057,\n",
       " 3: 0.107,\n",
       " 4: 0.148,\n",
       " 5: 0.165,\n",
       " 6: 0.169,\n",
       " 7: 0.2,\n",
       " 8: 0.208,\n",
       " 9: 0.215,\n",
       " 10: 0.216,\n",
       " 11: 0.23,\n",
       " 12: 0.311,\n",
       " 13: 0.342,\n",
       " 14: 0.433,\n",
       " 15: 0.467,\n",
       " 16: 0.513,\n",
       " 17: 0.535,\n",
       " 18: 0.544,\n",
       " 19: 0.643,\n",
       " 20: 0.653,\n",
       " 21: 0.751,\n",
       " 22: 0.764,\n",
       " 23: 0.838,\n",
       " 24: 0.905,\n",
       " 25: 0.972,\n",
       " 26: 1.32,\n",
       " 27: 1.586,\n",
       " 28: 1.613,\n",
       " 29: 2.313,\n",
       " 30: 2.744,\n",
       " 31: 4.168,\n",
       " 32: 4.579,\n",
       " 33: 5.426,\n",
       " 34: 6.68,\n",
       " 35: 7.578,\n",
       " 36: 7.547,\n",
       " 37: 7.578,\n",
       " 38: 7.754,\n",
       " 39: 8.071,\n",
       " 40: 8.792,\n",
       " 41: 11.593,\n",
       " 42: 12.73,\n",
       " 43: 14.827,\n",
       " 44: 14.92,\n",
       " 45: 15.0,\n",
       " 46: 15.572,\n",
       " 47: 15.837,\n",
       " 48: 16.607,\n",
       " 49: 16.707,\n",
       " 50: 16.558,\n",
       " 51: 18.078,\n",
       " 52: 19.175,\n",
       " 53: 21.083,\n",
       " 54: 21.684,\n",
       " 55: 23.09,\n",
       " 56: 23.218,\n",
       " 57: 26.614,\n",
       " 58: 36.471,\n",
       " 59: 40.24,\n",
       " 60: 47.557,\n",
       " 61: 49.97,\n",
       " 62: 56.746,\n",
       " 63: 71.234,\n",
       " 64: 82.463,\n",
       " 65: 91.978,\n",
       " 66: 107.308,\n",
       " 67: 104.625,\n",
       " 68: 153.578,\n",
       " 69: 209.25,\n",
       " 70: 214.615,\n",
       " 71: 223.2,\n",
       " 72: 229.315,\n",
       " 73: 220.263,\n",
       " 74: 229.315,\n",
       " 75: 249.851,\n",
       " 76: 298.929,\n",
       " 77: 293.684,\n",
       " 78: 304.364,\n",
       " 79: 310.0,\n",
       " 80: 321.923,\n",
       " 81: 429.231,\n",
       " 82: 669.6,\n",
       " 83: 697.5,\n",
       " 84: 760.909,\n",
       " 85: 837.0,\n",
       " 86: 1000.0,\n",
       " 87: 1000.0,\n",
       " 88: 1000.0,\n",
       " 89: 1000.0,\n",
       " 90: 1000.0,\n",
       " 91: 1000.0,\n",
       " 92: 1000.0,\n",
       " 93: 1000.0,\n",
       " 94: 1000.0,\n",
       " 95: 1000.0,\n",
       " 96: 1000.0,\n",
       " 97: 1000.0,\n",
       " 98: 1000.0,\n",
       " 99: 1000.0,\n",
       " 100: 1000.0,\n",
       " 101: 1000.0,\n",
       " 102: 1000.0,\n",
       " 103: 1000.0,\n",
       " 104: 1000.0,\n",
       " 105: 1000.0,\n",
       " 106: 1000.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight_dict = {}\n",
    "total_freq = sum([v for v in char_freq_dict.values()])\n",
    "\n",
    "for i, v in enumerate(vocab):\n",
    "    freq = char_freq_dict.get(v, 1)\n",
    "    class_weight_dict[i] = min(round(total_freq / (freq * 100), 3), 1_000.0)\n",
    "\n",
    "class_weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.71 s, sys: 93.8 ms, total: 6.8 s\n",
      "Wall time: 6.77 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1674000,), (88106,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y_train = vectorizer(y_train).numpy().flatten()\n",
    "y_test = vectorizer(y_test).numpy().flatten()\n",
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>,\n",
       " 26157)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = Dataset.from_tensor_slices((X_train, y_train)).shuffle(SHUFFLE_BUFFER).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "train_ds, len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>,\n",
       " 1377)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ds = Dataset.from_tensor_slices((X_test, y_test)).shuffle(SHUFFLE_BUFFER).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "val_ds, len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer LSTM_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer LSTM_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer LSTM_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"Text_Generation_Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 1)]               0         \n",
      "                                                                 \n",
      " TextVectorizer (TextVectori  (None, None)             0         \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " EmbeddingLayer (Embedding)  (None, None, 32)          3456      \n",
      "                                                                 \n",
      " LSTM_1 (LSTM)               (None, None, 128)         82432     \n",
      "                                                                 \n",
      " LSTM_2 (LSTM)               (None, None, 128)         131584    \n",
      "                                                                 \n",
      " LSTM_3 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " LR_1 (LeakyReLU)            (None, 128)               0         \n",
      "                                                                 \n",
      " Dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " Dense_2 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " LR_2 (LeakyReLU)            (None, 128)               0         \n",
      "                                                                 \n",
      " Dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " Dense_3 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " LR_3 (LeakyReLU)            (None, 128)               0         \n",
      "                                                                 \n",
      " Output (Dense)              (None, 107)               13803     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 412,395\n",
      "Trainable params: 412,395\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_lstm_model(char_count: int, embedding_dim: int = 32):\n",
    "    input_layer = tf.keras.Input(shape = (1,), dtype = tf.string, name = 'Input')\n",
    "\n",
    "    vectorizer_layer = vectorizer(input_layer)\n",
    "    embedding_layer = Embedding(char_count + 1, embedding_dim, name = 'EmbeddingLayer')(vectorizer_layer)\n",
    "\n",
    "    lstm_1 = LSTM(128, return_sequences = True, dropout = 0.05, recurrent_dropout = 0.05, name = 'LSTM_1')(embedding_layer)\n",
    "    lstm_2 = LSTM(128, return_sequences = True, dropout = 0.05, recurrent_dropout = 0.05, name = 'LSTM_2')(lstm_1)\n",
    "    lstm_3 = LSTM(128, dropout = 0.05, recurrent_dropout = 0.05, name = 'LSTM_3')(lstm_2)\n",
    "\n",
    "    dense_1 = Dense(128, name = 'Dense_1')(lstm_3)\n",
    "    lr_1 = LeakyReLU(name = 'LR_1')(dense_1)\n",
    "    dropout_1 = Dropout(0.1, name = 'Dropout_1')(lr_1)\n",
    "\n",
    "    dense_2 = Dense(128, name = 'Dense_2')(dropout_1)\n",
    "    lr_2 = LeakyReLU(name = 'LR_2')(dense_2)\n",
    "    dropout_2 = Dropout(0.1, name = 'Dropout_2')(lr_2)\n",
    "\n",
    "    dense_3 = Dense(128, name = 'Dense_3')(dropout_2)\n",
    "    lr_3 = LeakyReLU(name = 'LR_3')(dense_3)\n",
    "\n",
    "    output_layer = Dense(char_count, activation = 'softmax', name = \"Output\")(lr_3)\n",
    "\n",
    "    model = tf.keras.Model(inputs  = input_layer, outputs = output_layer, name = 'Text_Generation_Model')\n",
    "    model.compile(optimizer = Adam(LR), loss = 'sparse_categorical_crossentropy', metrics = ['sparse_categorical_accuracy'])\n",
    "    return model\n",
    "\n",
    "model = get_lstm_model(char_count, EMBEDDING_DIM)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25/25 [==============================] - 495s 19s/step - loss: 3.3308 - sparse_categorical_accuracy: 0.0231 - val_loss: 4.5371 - val_sparse_categorical_accuracy: 0.0375\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 499s 20s/step - loss: 2.7574 - sparse_categorical_accuracy: 0.0787 - val_loss: 4.0413 - val_sparse_categorical_accuracy: 0.0625\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 494s 20s/step - loss: 4.2027 - sparse_categorical_accuracy: 0.0194 - val_loss: 4.4809 - val_sparse_categorical_accuracy: 0.0172\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 494s 20s/step - loss: 6.3297 - sparse_categorical_accuracy: 0.0075 - val_loss: 4.4942 - val_sparse_categorical_accuracy: 0.0016\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 486s 19s/step - loss: 3.5889 - sparse_categorical_accuracy: 0.0188 - val_loss: 4.4398 - val_sparse_categorical_accuracy: 0.0016\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 492s 20s/step - loss: 3.4972 - sparse_categorical_accuracy: 0.0025 - val_loss: 4.3978 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 494s 20s/step - loss: 3.0709 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 4.2718 - val_sparse_categorical_accuracy: 0.0016\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 479s 19s/step - loss: 4.5134 - sparse_categorical_accuracy: 0.0056 - val_loss: 4.2473 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 484s 19s/step - loss: 2.4339 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 4.3763 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 483s 19s/step - loss: 4.0697 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 4.3968 - val_sparse_categorical_accuracy: 0.0016\n",
      "CPU times: user 1h 45min 34s, sys: 1h 21min 27s, total: 3h 7min 2s\n",
      "Wall time: 1h 21min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tensorboard = TensorBoard(log_dir = str(TB_LOGS))\n",
    "\n",
    "history = model.fit(\n",
    "        train_ds, \n",
    "        validation_data = val_ds, \n",
    "        epochs = EPOCHS, \n",
    "        steps_per_epoch = TRAIN_STEPS, \n",
    "        validation_steps = VAL_STEPS, \n",
    "        class_weight = class_weight_dict, \n",
    "        callbacks = [tensorboard]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 134s 1s/step - loss: 4.3967 - sparse_categorical_accuracy: 0.0027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.396735191345215, 0.0026562500279396772]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_ds.take(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "d it be?”\n",
      "\n",
      " “That is what Mr. Hilton Cubitt, of Riding Thorpe Manor, Norfolk,\n",
      " is very anxious to know. This little conundrum came by the first\n",
      " post, and he was to follow by the next train. There’s a ring at\n",
      " the bell, Watson. I should not be very much surprised if this\n",
      " were he.”\n",
      "\n",
      " A heavy step was heard upon the stairs, and an instant later\n",
      " there entered a tall, ruddy, clean-shaven gentleman, whose clear\n",
      " eyes and florid cheeks told of a life led far from the fogs of\n",
      " Baker Street. He seemed to bring a \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9202f5a3ac6b4e8bae08a988008a9022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting chars:   0%|          | 0/100 [00:00<?, ? char/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
      "CPU times: user 1min 18s, sys: 7.62 s, total: 1min 26s\n",
      "Wall time: 2min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sample_input = random.choice(X_train)\n",
    "print(f\"Input:\\n{sample_input}\")\n",
    "\n",
    "pred_output = ''\n",
    "\n",
    "for i in trange(100, desc = \"Predicting chars\", unit = \" char\"):\n",
    "    pred = model.predict([sample_input], verbose = False)\n",
    "    pred_char_id = pred.argmax()\n",
    "    pred_char = vocab[pred_char_id]\n",
    "    pred_output += pred_char\n",
    "    sample_input = sample_input[1:] + pred_char\n",
    "\n",
    "print(f\"Output:\\n{pred_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
