{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import random\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.notebook import trange\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset, AUTOTUNE\n",
    "from tensorflow.keras.layers import TextVectorization, LSTM, Embedding, Dropout, Dense, LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-31 07:26:57.456693: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-31 07:26:57.534588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-31 07:26:57.535052: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-31 07:26:57.540748: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'compute_capability': (7, 5), 'device_name': 'NVIDIA GeForce GTX 1650'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.get_device_details(gpu_devices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jul 31 07:26:58 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.57       Driver Version: 516.59       CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   54C    P8     2W /  N/A |      0MiB /  4096MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 7\n",
    "SEQ_LEN = 512\n",
    "VAL_SIZE = 0.05\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "LR = 5e-4\n",
    "SHUFFLE_BUFFER = BATCH_SIZE * 20\n",
    "EMBEDDING_DIM = 32\n",
    "DROPOUT_RATIO = 0.2\n",
    "TRAIN_STEPS = 2500\n",
    "VAL_STEPS = 250\n",
    "EARLY_STOP_PATIENCE = 3\n",
    "\n",
    "TB_LOGS = Path(\"tb_logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "TB_LOGS.mkdir(exist_ok = True, parents = True)\n",
    "\n",
    "MODELS_DIR = Path(\"models\")\n",
    "MODELS_DIR.mkdir(exist_ok = True, parents = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: ' it was\\n for Lady Hilda Trelawney Hope that Sherlock Holmes inquired. We\\n were shown into the morning-room.\\n\\n “Mr. Holmes!” said the lady, and her face was pink with her\\n indignation. “This is surely most unfair and ungenerous upon your\\n part. I desired, as I have explained, to keep my visit to you a\\n secret, lest my husband should think that I was intruding into\\n his affairs. And yet you compromise me by coming here and so\\n showing that there are business relations between us.”\\n\\n “Unfortunately, madam, I h'\n",
      "Output: a\n",
      "\n",
      "Input: 'ghing; “but since, as you said\\njust now, there has been no crime committed, and no harm done save the\\nloss of a goose, all this seems to be rather a waste of energy.”\\n\\nSherlock Holmes had opened his mouth to reply, when the door flew open,\\nand Peterson, the commissionaire, rushed into the apartment with\\nflushed cheeks and the face of a man who is dazed with astonishment.\\n\\n“The goose, Mr. Holmes! The goose, sir!” he gasped.\\n\\n“Eh? What of it, then? Has it returned to life and flapped off through\\nthe kitchen w'\n",
      "Output: i\n",
      "\n",
      "Input: 'ime to wait for that. It came just as\\n we had finished our tea. “The cottage is still tenanted,” it\\n said. “Have seen the face again at the window. Will meet the\\n seven o’clock train, and will take no steps until you arrive.”\\n\\n He was waiting on the platform when we stepped out, and we could\\n see in the light of the station lamps that he was very pale, and\\n quivering with agitation.\\n\\n “They are still there, Mr. Holmes,” said he, laying his hand hard\\n upon my friend’s sleeve. “I saw lights in the cottage as '\n",
      "Output: I\n",
      "\n",
      "Input: 'f this very remarkable Park Lane Mystery,\\n which not only appealed to me by its own merits, but which seemed\\n to offer some most peculiar personal opportunities. I came over\\n at once to London, called in my own person at Baker Street, threw\\n Mrs. Hudson into violent hysterics, and found that Mycroft had\\n preserved my rooms and my papers exactly as they had always been.\\n So it was, my dear Watson, that at two o’clock to-day I found\\n myself in my old armchair in my own old room, and only wishing\\n that I could'\n",
      "Output:  \n",
      "\n",
      "Input: ' patient. “Then that explains what the girl\\nsaid.”\\n\\n“Undoubtedly. It is quite clear that the colonel was a cool and\\ndesperate man, who was absolutely determined that nothing should stand\\nin the way of his little game, like those out-and-out pirates who will\\nleave no survivor from a captured ship. Well, every moment now is\\nprecious, so if you feel equal to it we shall go down to Scotland Yard\\nat once as a preliminary to starting for Eyford.”\\n\\nSome three hours or so afterwards we were all in the train togethe'\n",
      "Output: r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "books = Path(\"../Data/Text/Sherlock_Holmes/\").rglob(\"*.txt\")\n",
    "\n",
    "for book in books:\n",
    "    with book.open('r', encoding = 'utf-8') as book_file:\n",
    "        book_data = book_file.read()\n",
    "        book_data = re.sub(\"[ ]+\", \" \", book_data)\n",
    "        char_len = len(book_data)\n",
    "\n",
    "        for i in range(0, char_len - SEQ_LEN):\n",
    "            X.append(book_data[i : i + SEQ_LEN])\n",
    "            y.append(book_data[i + SEQ_LEN])\n",
    "\n",
    "for i in np.random.randint(0, len(X), 5):\n",
    "    print(f'Input: {X[i]!r}')\n",
    "    print(f'Output: {y[i]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1762106, 1762106)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1674000, 1674000, 88106, 88106)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = VAL_SIZE, random_state = RANDOM_STATE)\n",
    "\n",
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ', 295464),\n",
       " ('e', 155851),\n",
       " ('t', 112814),\n",
       " ('a', 101599),\n",
       " ('o', 98853),\n",
       " ('n', 83839),\n",
       " ('h', 80451),\n",
       " ('i', 77714),\n",
       " ('s', 77639),\n",
       " ('r', 72665),\n",
       " ('d', 53827),\n",
       " ('l', 48896),\n",
       " ('u', 38653),\n",
       " ('\\n', 35880),\n",
       " ('m', 32644),\n",
       " ('c', 31278),\n",
       " ('w', 30752),\n",
       " ('f', 26027),\n",
       " ('y', 25655),\n",
       " ('g', 22287)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_freq_dict = Counter(y_train)\n",
    "char_freq_dict.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(X)\n",
    "del(y)\n",
    "del(book_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 793 ms, sys: 565 ms, total: 1.36 s\n",
      "Wall time: 2.22 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-31 07:27:04.843743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-31 07:27:04.846745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-31 07:27:04.847271: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-31 07:27:04.847727: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-31 07:27:06.592551: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-31 07:27:06.592910: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-31 07:27:06.592926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-07-31 07:27:06.593183: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-31 07:27:06.593305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2103 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "vectorizer = TextVectorization(standardize = None, split = \"character\", name = 'TextVectorizer')\n",
    "vocab_json = Path(\"vocab.json\")\n",
    "\n",
    "if vocab_json.exists():\n",
    "    with vocab_json.open(\"r\") as vocab_file:\n",
    "        vocab = json.load(vocab_file)[\"vocab\"]\n",
    "    \n",
    "    vectorizer.set_vocabulary(vocab)\n",
    "else:\n",
    "    vectorizer.adapt(X_train)\n",
    "    vocab = vectorizer.get_vocabulary()[2:]\n",
    "\n",
    "    with vocab_json.open(\"w\") as vocab_file:\n",
    "        json.dump({\"vocab\": vocab}, vocab_file)\n",
    "\n",
    "vocab = vectorizer.get_vocabulary()\n",
    "char_count = len(vocab)\n",
    "char_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 125.08,\n",
       " 1: 125.08,\n",
       " 2: 0.23,\n",
       " 3: 0.32,\n",
       " 4: 0.37,\n",
       " 5: 0.39,\n",
       " 6: 0.4,\n",
       " 7: 0.43,\n",
       " 8: 0.44,\n",
       " 9: 0.45,\n",
       " 10: 0.45,\n",
       " 11: 0.46,\n",
       " 12: 0.54,\n",
       " 13: 0.57,\n",
       " 14: 0.64,\n",
       " 15: 0.66,\n",
       " 16: 0.69,\n",
       " 17: 0.71,\n",
       " 18: 0.71,\n",
       " 19: 0.78,\n",
       " 20: 0.78,\n",
       " 21: 0.84,\n",
       " 22: 0.85,\n",
       " 23: 0.89,\n",
       " 24: 0.92,\n",
       " 25: 0.95,\n",
       " 26: 1.11,\n",
       " 27: 1.22,\n",
       " 28: 1.23,\n",
       " 29: 1.47,\n",
       " 30: 1.6,\n",
       " 31: 1.97,\n",
       " 32: 2.07,\n",
       " 33: 2.25,\n",
       " 34: 2.5,\n",
       " 35: 2.66,\n",
       " 36: 2.66,\n",
       " 37: 2.66,\n",
       " 38: 2.69,\n",
       " 39: 2.75,\n",
       " 40: 2.87,\n",
       " 41: 3.29,\n",
       " 42: 3.45,\n",
       " 43: 3.72,\n",
       " 44: 3.73,\n",
       " 45: 3.74,\n",
       " 46: 3.81,\n",
       " 47: 3.85,\n",
       " 48: 3.94,\n",
       " 49: 3.95,\n",
       " 50: 3.93,\n",
       " 51: 4.11,\n",
       " 52: 4.23,\n",
       " 53: 4.44,\n",
       " 54: 4.5,\n",
       " 55: 4.65,\n",
       " 56: 4.66,\n",
       " 57: 4.99,\n",
       " 58: 5.84,\n",
       " 59: 6.13,\n",
       " 60: 6.67,\n",
       " 61: 6.83,\n",
       " 62: 7.28,\n",
       " 63: 8.16,\n",
       " 64: 8.78,\n",
       " 65: 9.27,\n",
       " 66: 10.01,\n",
       " 67: 9.89,\n",
       " 68: 11.98,\n",
       " 69: 13.98,\n",
       " 70: 14.16,\n",
       " 71: 14.44,\n",
       " 72: 14.35,\n",
       " 73: 14.64,\n",
       " 74: 14.64,\n",
       " 75: 15.28,\n",
       " 76: 16.71,\n",
       " 77: 16.57,\n",
       " 78: 16.87,\n",
       " 79: 17.02,\n",
       " 80: 17.35,\n",
       " 81: 20.03,\n",
       " 82: 25.02,\n",
       " 83: 25.53,\n",
       " 84: 26.67,\n",
       " 85: 27.97,\n",
       " 86: 39.55,\n",
       " 87: 44.22,\n",
       " 88: 44.22,\n",
       " 89: 51.06,\n",
       " 90: 51.06,\n",
       " 91: 62.54,\n",
       " 92: 55.94,\n",
       " 93: 62.54,\n",
       " 94: 125.08,\n",
       " 95: 125.08,\n",
       " 96: 72.21,\n",
       " 97: 72.21,\n",
       " 98: 72.21,\n",
       " 99: 125.08,\n",
       " 100: 88.44,\n",
       " 101: 88.44,\n",
       " 102: 88.44,\n",
       " 103: 125.08,\n",
       " 104: 125.08,\n",
       " 105: 125.08,\n",
       " 106: 125.08}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight_dict = {}\n",
    "total_freq = sum([v for v in char_freq_dict.values()])\n",
    "\n",
    "for i, v in enumerate(vocab):\n",
    "    freq = char_freq_dict.get(v, 1)\n",
    "    class_weight_dict[i] = round(np.sqrt(total_freq / (freq * char_count)), 2)\n",
    "\n",
    "class_weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.54 s, sys: 192 ms, total: 6.74 s\n",
      "Wall time: 6.76 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1674000,), (88106,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y_train = vectorizer(y_train).numpy().flatten()\n",
    "y_test = vectorizer(y_test).numpy().flatten()\n",
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = Dataset.from_tensor_slices((X_train, y_train)).shuffle(SHUFFLE_BUFFER).repeat().batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ds = Dataset.from_tensor_slices((X_test, y_test)).shuffle(SHUFFLE_BUFFER).repeat().batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Text_Generation_Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 1)]               0         \n",
      "                                                                 \n",
      " TextVectorizer (TextVectori  (None, None)             0         \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " EmbeddingLayer (Embedding)  (None, None, 32)          3456      \n",
      "                                                                 \n",
      " LSTM_1 (LSTM)               (None, None, 512)         1116160   \n",
      "                                                                 \n",
      " LSTM_2 (LSTM)               (None, 256)               787456    \n",
      "                                                                 \n",
      " BN_1 (BatchNormalization)   (None, 256)               1024      \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " LR_1 (LeakyReLU)            (None, 256)               0         \n",
      "                                                                 \n",
      " Dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " Dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " LR_2 (LeakyReLU)            (None, 128)               0         \n",
      "                                                                 \n",
      " Dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " BN_2 (BatchNormalization)   (None, 128)               512       \n",
      "                                                                 \n",
      " Dense_3 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " LR_3 (LeakyReLU)            (None, 128)               0         \n",
      "                                                                 \n",
      " Output (Dense)              (None, 107)               13803     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,037,611\n",
      "Trainable params: 2,036,843\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_lstm_model(char_count: int, embedding_dim: int = 32):\n",
    "    input_layer = tf.keras.Input(shape = (1,), dtype = tf.string, name = 'Input')\n",
    "\n",
    "    vectorizer_layer = vectorizer(input_layer)\n",
    "    embedding_layer = Embedding(char_count + 1, embedding_dim, name = 'EmbeddingLayer')(vectorizer_layer)\n",
    "\n",
    "    lstm_1 = LSTM(512, return_sequences = True, dropout = DROPOUT_RATIO, name = 'LSTM_1')(embedding_layer)\n",
    "    lstm_2 = LSTM(256, dropout = DROPOUT_RATIO, name = 'LSTM_2')(lstm_1)\n",
    "    bn_1 = BatchNormalization(name = 'BN_1')(lstm_2)\n",
    "\n",
    "    dense_1 = Dense(256, name = 'Dense_1')(bn_1)\n",
    "    lr_1 = LeakyReLU(name = 'LR_1')(dense_1)\n",
    "    dropout_1 = Dropout(DROPOUT_RATIO, name = 'Dropout_1')(lr_1)\n",
    "\n",
    "    dense_2 = Dense(128, name = 'Dense_2')(dropout_1)\n",
    "    lr_2 = LeakyReLU(name = 'LR_2')(dense_2)\n",
    "    dropout_2 = Dropout(DROPOUT_RATIO, name = 'Dropout_2')(lr_2)\n",
    "    bn_2 = BatchNormalization(name = 'BN_2')(dropout_2)\n",
    "\n",
    "    dense_3 = Dense(128, name = 'Dense_3')(bn_2)\n",
    "    lr_3 = LeakyReLU(name = 'LR_3')(dense_3)\n",
    "\n",
    "    output_layer = Dense(char_count, activation = 'softmax', name = \"Output\")(lr_3)\n",
    "\n",
    "    model = tf.keras.Model(inputs  = input_layer, outputs = output_layer, name = 'Text_Generation_Model')\n",
    "    model.compile(optimizer = Adam(LR), loss = 'sparse_categorical_crossentropy', metrics = ['sparse_categorical_accuracy'])\n",
    "    return model\n",
    "\n",
    "model = get_lstm_model(char_count, EMBEDDING_DIM)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-31 07:27:39.130986: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 1316s 523ms/step - loss: 1.7576 - sparse_categorical_accuracy: 0.2606 - val_loss: 3.1701 - val_sparse_categorical_accuracy: 0.1863\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 1310s 524ms/step - loss: 1.6032 - sparse_categorical_accuracy: 0.3130 - val_loss: 2.3830 - val_sparse_categorical_accuracy: 0.3060\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 1313s 525ms/step - loss: 1.5527 - sparse_categorical_accuracy: 0.3324 - val_loss: 2.7714 - val_sparse_categorical_accuracy: 0.2616\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 1317s 527ms/step - loss: 1.5386 - sparse_categorical_accuracy: 0.3414 - val_loss: 2.2247 - val_sparse_categorical_accuracy: 0.3647\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 1314s 526ms/step - loss: 1.4833 - sparse_categorical_accuracy: 0.3560 - val_loss: 2.1233 - val_sparse_categorical_accuracy: 0.3778\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 1311s 524ms/step - loss: 1.4437 - sparse_categorical_accuracy: 0.3673 - val_loss: 2.1612 - val_sparse_categorical_accuracy: 0.3833\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 1308s 523ms/step - loss: 1.6943 - sparse_categorical_accuracy: 0.2890 - val_loss: 2.1254 - val_sparse_categorical_accuracy: 0.3959\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 1311s 524ms/step - loss: 1.4353 - sparse_categorical_accuracy: 0.3778 - val_loss: 2.0446 - val_sparse_categorical_accuracy: 0.3959\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 1310s 524ms/step - loss: 1.3946 - sparse_categorical_accuracy: 0.3851 - val_loss: 1.9601 - val_sparse_categorical_accuracy: 0.4211\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 1312s 525ms/step - loss: 1.3816 - sparse_categorical_accuracy: 0.3940 - val_loss: 1.9792 - val_sparse_categorical_accuracy: 0.4141\n",
      "CPU times: user 2h 27min 43s, sys: 1h 8min 54s, total: 3h 36min 38s\n",
      "Wall time: 3h 38min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "earlystop = EarlyStopping(patience = EARLY_STOP_PATIENCE, restore_best_weights = True)\n",
    "tensorboard = TensorBoard(log_dir = str(TB_LOGS))\n",
    "\n",
    "history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data = val_ds,\n",
    "        epochs = EPOCHS,\n",
    "        steps_per_epoch = TRAIN_STEPS,\n",
    "        validation_steps = VAL_STEPS,\n",
    "        class_weight = class_weight_dict,\n",
    "        callbacks = [earlystop, tensorboard]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 97s 194ms/step - loss: 1.9763 - sparse_categorical_accuracy: 0.4148\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.9762729406356812, 0.4148281216621399]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_ds.take(500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      ". There must have been several in it, and they must have been men\n",
      "of resource and determination. Their papers they mean to have, be the\n",
      "holder of them who it may. In this way you see K. K. K. ceases to be\n",
      "the initials of an individual and becomes the badge of a society.”\n",
      "\n",
      "“But of what society?”\n",
      "\n",
      "“Have you never—” said Sherlock Holmes, bending forward and sinking his\n",
      "voice—“have you never heard of the Ku Klux Klan?”\n",
      "\n",
      "“I never have.”\n",
      "\n",
      "Holmes turned over the leaves of the book upon his knee. “Here it is,”\n",
      "said\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d19e26926014476b2554b42522cbbb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting chars:   0%|          | 0/100 [00:00<?, ? char/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      " Holmes; “Which I was may the prack, which I was sucked the project Gutenbed.”\n",
      "\n",
      "“And the Carmer.”\n",
      "\n",
      "“\n",
      "CPU times: user 29.4 s, sys: 2.3 s, total: 31.7 s\n",
      "Wall time: 30.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sample_input = random.choice(X_train)\n",
    "print(f\"Input:\\n{sample_input}\")\n",
    "\n",
    "pred_output = ''\n",
    "\n",
    "for i in trange(100, desc = \"Predicting chars\", unit = \" char\"):\n",
    "    pred = model.predict([sample_input], verbose = False)\n",
    "    pred_char_id = pred.argmax()\n",
    "    pred_char = vocab[pred_char_id]\n",
    "    pred_output += pred_char\n",
    "    sample_input = sample_input[1:] + pred_char\n",
    "\n",
    "print(f\"Output:\\n{pred_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(MODELS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
